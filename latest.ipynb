{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Research (DDG-Powered Agentic Pipeline)**\n",
    "\n",
    "This project is a **small but complete agentic research pipeline** that plans web searches, gathers **high-signal snippets** via DuckDuckGo, and synthesizes a **long-form report** with inline citations.  \n",
    "\n",
    "It also includes:\n",
    "- A **Gradio UI** for interactive use.\n",
    "- An optional **SendGrid email step** to deliver the final report as HTML.\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ **How It Works (Bird‚Äôs-Eye View)**\n",
    "\n",
    "1. **`PlannerAgent`** ‚Äî Analyzes your topic and proposes exactly **HOW_MANY_SEARCHES** focused queries, with clear reasoning for each.\n",
    "2. **Search Agent (DuckDuckGo)** ‚Äî Runs each query via a tool, producing compact summaries with a ‚ÄúSources‚Äù list.\n",
    "3. **`WriterAgent`** ‚Äî Combines mini-summaries into a long report with inline citations `[1]`, `[2]`, etc., and a matching `final_citations` list.\n",
    "4. **(Optional) Email Agent** ‚Äî Sends the report in **nicely formatted HTML**.\n",
    "5. **Gradio UI** ‚Äî Streams progress and allows downloading the final Markdown.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† **Agents at a Glance**\n",
    "\n",
    "### **1. PlannerAgent ‚Äî ‚ÄúWhat should I search?‚Äù**\n",
    "- Generates **3 targeted search phrases** to cover:\n",
    "  - Background\n",
    "  - Trends\n",
    "  - Data\n",
    "  - Breadth\n",
    "- Ensures maximum relevance and minimal overlap.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Search Agent (DuckDuckGo) ‚Äî ‚ÄúGet me credible snippets quickly.‚Äù**\n",
    "- Executes `ddg_search` **exactly once** per phrase.\n",
    "- Summarizes in a few paragraphs.\n",
    "- Appends a **small, credible Sources list**.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. WriterAgent (Synthesizer) ‚Äî ‚ÄúTurn everything into a coherent report.‚Äù**\n",
    "- Builds a **multi-section Markdown report** (target length: **3‚Äì6k words**).\n",
    "- Adds **inline citations** `[n]` that correspond to an **ordered final_citations** list.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Email Agent ‚Äî ‚ÄúSend it.‚Äù**\n",
    "- Uses **SendGrid** to deliver the final HTML-formatted report directly to recipients.\n",
    "\n",
    "---\n",
    "\n",
    "## üé® **User Experience**\n",
    "- **Interactive Gradio UI** to visualize progress.\n",
    "- Live streaming of agent outputs.\n",
    "- **Downloadable Markdown** for offline use.\n",
    "- Optional **email delivery** for easy sharing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, WebSearchTool, trace, Runner, gen_trace_id, function_tool, ModelSettings\n",
    "from agents.model_settings import ModelSettings\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "import sendgrid\n",
    "import os\n",
    "from sendgrid.helpers.mail import Mail, Email, To, Content\n",
    "from typing import List, Dict, Any\n",
    "from IPython.display import display, Markdown\n",
    "import os, asyncio, textwrap\n",
    "from typing import List, Dict, Optional, Any\n",
    "from pydantic import BaseModel, Field\n",
    "import gradio as gr\n",
    "from ddgs import DDGS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fix TLS issues in some environments (VS Code / Windows / corp proxies)\n",
    "\n",
    "import os, certifi\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()  \n",
    "\n",
    "import sendgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# 1) DuckDuckGo tool\n",
    "# ======================================================================================\n",
    "ddg = DDGS()\n",
    "\n",
    "# ---------- DDG tool ----------\n",
    "@function_tool\n",
    "def ddg_search(query: str,\n",
    "               max_results: int = 10,\n",
    "               region: str = \"us-en\",\n",
    "               safesearch: str = \"moderate\") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Run a DuckDuckGo search and return a list of results.\n",
    "    Each result includes: title, url, snippet.\n",
    "    \"\"\"\n",
    "    hits = ddg.text(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        region=region,\n",
    "        safesearch=safesearch,\n",
    "        verbose=True\n",
    "    )\n",
    "    results: List[Dict[str, Any]] = []\n",
    "    for h in hits:\n",
    "        url = h.get(\"href\") or h.get(\"url\") or \"\"\n",
    "        if not url.startswith(\"http\"):\n",
    "            continue\n",
    "        results.append({\n",
    "            \"title\": h.get(\"title\", \"\") or \"\",\n",
    "            \"url\": url,\n",
    "            \"snippet\": h.get(\"body\") or h.get(\"snippet\") or \"\"\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# ---------- Search agent (uses DDG tool) ----------\n",
    "SEARCH_INSTRUCTIONS = (\n",
    "    \"You are a research assistant. Given a search term, call `ddg_search` exactly once to fetch results, \"\n",
    "    \"then produce a elaborate summary in 4-5 paragraphs (>=1000 words). Capture only the key points‚Äîno fluff. \"\n",
    "    \"Use the result titles and snippets only; do not browse further.\\n\\n\"\n",
    "    \"After the summary, add a 'Sources' section listing 2‚Äì4 of the most relevant items as:\\n\"\n",
    "    \"[1] Title ‚Äî URL\\n[2] Title ‚Äî URL\\n\"\n",
    ")\n",
    "\n",
    "search_agent = Agent(\n",
    "    name=\"Search agent (DuckDuckGo)\",\n",
    "    instructions=SEARCH_INSTRUCTIONS,\n",
    "    tools=[ddg_search],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    model_settings=ModelSettings(tool_choice=\"required\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# message = \"Latest AI Agent frameworks in 2025\"\n",
    "\n",
    "# with trace(\"Search\"):\n",
    "#     result = await Runner.run(search_agent, message)\n",
    "\n",
    "# display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# 2) PlannerAgent ‚Äî structured outputs (queries with reasons)\n",
    "# ======================================================================================\n",
    "HOW_MANY_SEARCHES = 3\n",
    "\n",
    "INSTRUCTIONS = f\"You are a helpful research assistant. Given a query, come up with a set of web searches \\\n",
    "to perform to best answer the query. Output {HOW_MANY_SEARCHES} terms to query for.\"\n",
    "\n",
    "\n",
    "class WebSearchItem(BaseModel):\n",
    "    reason: str = Field(description=\"Your reasoning for why this search is important to the query.\")\n",
    "\n",
    "    query: str = Field(description=\"The search term to use for the web search.\")\n",
    "\n",
    "\n",
    "class WebSearchPlan(BaseModel):\n",
    "    searches: list[WebSearchItem] = Field(description=\"A list of web searches to perform to best answer the query.\")\n",
    "\n",
    "\n",
    "planner_agent = Agent(\n",
    "    name=\"PlannerAgent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    output_type=WebSearchPlan,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# message = \"Latest AI Agent frameworks in 2025\"\n",
    "\n",
    "# with trace(\"Search\"):\n",
    "#     result = await Runner.run(planner_agent, message)\n",
    "#     print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# 3) Email agent (optional)\n",
    "# ======================================================================================\n",
    "\n",
    "\n",
    "INSTRUCTIONS = \"\"\"You are able to send a nicely formatted HTML email based on a detailed report.\n",
    "You will be provided with a detailed report. You should use your tool to send one email, providing the \n",
    "report converted into clean, well presented HTML with an appropriate subject line.\"\"\"\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def send_email(subject: str, html_body: str) -> Dict[str, str]:\n",
    "    \"\"\" Send out an email with the given subject and HTML body \"\"\"\n",
    "    sg = sendgrid.SendGridAPIClient(api_key=os.environ.get('SENDGRID_API_KEY'))\n",
    "    from_email = Email(\"garodisk@mail.uc.edu\") # Change this to your verified email\n",
    "    to_email = To(\"saketgarodia1@gmail.com\") # Change this to your email\n",
    "    content = Content(\"text/html\", html_body)\n",
    "    mail = Mail(from_email, to_email, subject, content).get()\n",
    "    response = sg.client.mail.send.post(request_body=mail)\n",
    "    return {\"status\": \"success\"}\n",
    "\n",
    "\n",
    "\n",
    "email_agent = Agent(\n",
    "    name=\"Email agent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    tools=[send_email],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    model_settings=ModelSettings(tool_choice=\"required\"), \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# 4) WriterAgent (Synthesizer) ‚Äî long-form report with citations\n",
    "# ======================================================================================\n",
    "# \n",
    "WRITER_INSTRUCTIONS = (\n",
    "    \"You are a senior researcher tasked with writing a cohesive, deep report.\\n\"\n",
    "    \"You will be given the original query and a set of mini-summaries produced by assistants. \"\n",
    "    \"Each mini-summary ends with a 'Sources' list. Use ONLY the information in those summaries and sources; \"\n",
    "    \"do not invent facts.\\n\\n\"\n",
    "    \"Tasks:\\n\"\n",
    "    \"1) Write an outline (headings only) for the report.\\n\"\n",
    "    \"2) Write a long-form Markdown report (aim 3,000‚Äì6,000 words) with clear headings/subheadings. \"\n",
    "    \"Synthesize across the summaries, compare viewpoints, highlight agreements/disagreements, and avoid duplication. \"\n",
    "    \"Where you reference specific facts, insert inline citations like [1], [2], etc. Map these to the ordered list \"\n",
    "    \"of final citations you provide at the end.\\n\"\n",
    "    \"3) Provide a 3‚Äì5 sentence executive summary.\\n\"\n",
    "    \"4) Provide 3‚Äì6 follow-up research topics.\\n\\n\"\n",
    "    \"Citation rules:\\n\"\n",
    "    \"- Only cite items that appear in the provided 'Sources' lists. Use the exact URLs.\\n\"\n",
    "    \"- Ensure the first time you cite a source in the body, it becomes [1], then [2], etc., in order of first mention. \"\n",
    "    \"Your `final_citations` must match that order exactly. Please don't forget to cite sources in the end of the report\\n\"\n",
    ")\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    url: str = Field(description=\"Exact source URL used in the report\")\n",
    "    title: Optional[str] = Field(default=None, description=\"Page/article title, if known\")\n",
    "\n",
    "class ReportData(BaseModel):\n",
    "    short_summary: str = Field(description=\"Executive summary (3‚Äì5 sentences).\")\n",
    "    outline_markdown: str = Field(description=\"Markdown outline (headings and bullets).\")\n",
    "    markdown_report: str = Field(description=\"Full long-form Markdown report with inline [n] citations.\")\n",
    "    follow_up_questions: List[str] = Field(description=\"3‚Äì6 suggested topics to research further.\")\n",
    "    final_citations: List[Citation] = Field(\n",
    "        description=\"Ordered list of sources used (maps to [1..N]).\"\n",
    "    )\n",
    "\n",
    "writer_agent = Agent(\n",
    "    name=\"WriterAgent (Synthesizer)\",\n",
    "    instructions=WRITER_INSTRUCTIONS,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    output_type=ReportData,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# 5) Small console helpers (pretty progress)\n",
    "# ======================================================================================\n",
    "\n",
    "RESET = \"\\x1b[0m\"\n",
    "BOLD  = \"\\x1b[1m\"\n",
    "DIM   = \"\\x1b[2m\"\n",
    "CYAN  = \"\\x1b[36m\"\n",
    "GREEN = \"\\x1b[32m\"\n",
    "YELL  = \"\\x1b[33m\"\n",
    "MAG   = \"\\x1b[35m\"\n",
    "\n",
    "def info(msg):    print(f\"{CYAN}‚ÑπÔ∏è  {msg}{RESET}\")\n",
    "def step(msg):    print(f\"{GREEN}‚úÖ {msg}{RESET}\")\n",
    "def warn(msg):    print(f\"{YELL}‚ö†Ô∏è  {msg}{RESET}\")\n",
    "def doing(msg):   print(f\"{MAG}üîé {msg}{RESET}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# 6) Orchestration helpers\n",
    "# ======================================================================================\n",
    "\n",
    "async def plan_searches(query: str) -> WebSearchPlan:\n",
    "    result = await Runner.run(planner_agent, f\"Query: {query}\")\n",
    "    plan = result.final_output\n",
    "    # pretty print\n",
    "    info(\"Planned search phrases:\")\n",
    "    for i, it in enumerate(plan.searches, 1):\n",
    "        print(f\"  {i}. {BOLD}{it.query}{RESET} {DIM}‚Äî {it.reason}{RESET}\")\n",
    "    return plan\n",
    "\n",
    "async def search_one(item: WebSearchItem) -> str:\n",
    "    # You can include the reason in the prompt for context, but the agent will call the tool.\n",
    "    doing(f\"Searching: {item.query}\")\n",
    "    input_msg = f\"Search term: {item.query}\\nReason: {item.reason}\"\n",
    "    result = await Runner.run(search_agent, input_msg, max_turns=4)\n",
    "    step(f\"Done: {item.query}\")\n",
    "    return result.final_output  # a Markdown 2‚Äì3 paragraph summary + Sources list\n",
    "\n",
    "async def perform_searches(plan: WebSearchPlan) -> List[str]:\n",
    "    # Run them concurrently\n",
    "    tasks = [asyncio.create_task(search_one(it)) for it in plan.searches]\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "def build_writer_input(original_query: str, mini_summaries: List[str]) -> str:\n",
    "    # Plain text payload, no JSON. Clear delimiters.\n",
    "    blocks = []\n",
    "    blocks.append(f\"Original query:\\n{original_query}\\n\")\n",
    "    blocks.append(\"=== MINI-SUMMARIES START ===\")\n",
    "    for i, s in enumerate(mini_summaries, 1):\n",
    "        blocks.append(f\"\\n--- Summary {i} ---\\n{s}\\n\")\n",
    "    blocks.append(\"=== MINI-SUMMARIES END ===\\n\")\n",
    "    return \"\\n\".join(blocks)\n",
    "\n",
    "async def write_report(original_query: str, mini_summaries: List[str]) -> ReportData:\n",
    "    payload = build_writer_input(original_query, mini_summaries)\n",
    "    result = await Runner.run(writer_agent, payload, max_turns=4)\n",
    "    return result.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# 7) Actual Research\n",
    "# ======================================================================================\n",
    "\n",
    "async def run_research(query: str):\n",
    "    with trace(\"Deep Research (DDG)\"):\n",
    "        print(\"Planning...\")\n",
    "        plan = await plan_searches(query)\n",
    "\n",
    "        print(\"Searching...\")\n",
    "        mini_summaries = await perform_searches(plan)\n",
    "\n",
    "        print(\"Synthesizing...\")\n",
    "        report = await write_report(query, mini_summaries)\n",
    "\n",
    "        # Optional: await Runner.run(email_agent, report.markdown_report)\n",
    "        return plan, mini_summaries, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# 8) Notebook helpers (pretty rendering of results)\n",
    "# ======================================================================================\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def show_report(report: ReportData, mini_summaries: List[str] | None = None):\n",
    "    # Body\n",
    "    display(Markdown(report.markdown_report))\n",
    "\n",
    "    # References (if present)\n",
    "    if getattr(report, \"final_citations\", None):\n",
    "        lines = []\n",
    "        for i, c in enumerate(report.final_citations, 1):\n",
    "            title = (c.title or c.url).replace(\"[\", r\"\\[\").replace(\"]\", r\"\\]\")\n",
    "            lines.append(f\"{i}. [{title}]({c.url})\")\n",
    "        display(Markdown(\"### References\\n\\n\" + \"\\n\".join(lines)))\n",
    "    else:\n",
    "        display(Markdown(\"_No references returned by the writer._\"))\n",
    "\n",
    "def show_plan(plan: WebSearchPlan):\n",
    "    rows = [f\"{i}. **{it.query}** ‚Äî {it.reason}\" for i, it in enumerate(plan.searches, 1)]\n",
    "    display(Markdown(\"### Planned search phrases\\n\\n\" + \"\\n\".join(rows)))\n",
    "\n",
    "def show_mini_summaries(mini_summaries: List[str]):\n",
    "    if not mini_summaries:\n",
    "        display(Markdown(\"_No mini-summaries produced._\"))\n",
    "        return\n",
    "    parts = [\"### Mini-summaries\"]\n",
    "    for i, s in enumerate(mini_summaries, 1):\n",
    "        parts.append(f\"<details><summary><b>Summary {i}</b></summary>\\n\\n{s}\\n\\n</details>\")\n",
    "    display(Markdown(\"\\n\\n\".join(parts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning...\n",
      "\u001b[36m‚ÑπÔ∏è  Planned search phrases:\u001b[0m\n",
      "  1. \u001b[1mtop AI agent frameworks 2023\u001b[0m \u001b[2m‚Äî To find authoritative and comprehensive lists of AI agent frameworks ranked by usage, popularity, or functional capability.\u001b[0m\n",
      "  2. \u001b[1mbest AI agent frameworks comparison\u001b[0m \u001b[2m‚Äî To discover community discussions and expert opinions on the most effective AI agent frameworks currently available.\u001b[0m\n",
      "  3. \u001b[1mAI frameworks ranking performance 2023\u001b[0m \u001b[2m‚Äî To gather metrics and evaluation criteria that rank AI agent frameworks based on performance and features.\u001b[0m\n",
      "Searching...\n",
      "\u001b[35müîé Searching: top AI agent frameworks 2023\u001b[0m\n",
      "\u001b[35müîé Searching: best AI agent frameworks comparison\u001b[0m\n",
      "\u001b[35müîé Searching: AI frameworks ranking performance 2023\u001b[0m\n",
      "\u001b[32m‚úÖ Done: best AI agent frameworks comparison\u001b[0m\n",
      "\u001b[32m‚úÖ Done: top AI agent frameworks 2023\u001b[0m\n",
      "\u001b[32m‚úÖ Done: AI frameworks ranking performance 2023\u001b[0m\n",
      "Synthesizing...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Planned search phrases\n",
       "\n",
       "1. **top AI agent frameworks 2023** ‚Äî To find authoritative and comprehensive lists of AI agent frameworks ranked by usage, popularity, or functional capability.\n",
       "2. **best AI agent frameworks comparison** ‚Äî To discover community discussions and expert opinions on the most effective AI agent frameworks currently available.\n",
       "3. **AI frameworks ranking performance 2023** ‚Äî To gather metrics and evaluation criteria that rank AI agent frameworks based on performance and features."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Mini-summaries\n",
       "\n",
       "<details><summary><b>Summary 1</b></summary>\n",
       "\n",
       "The search for the top AI agent frameworks in 2023 reveals a variety of options tailored for different use cases, emphasizing functionality, ease of use, and advanced capabilities. Notable frameworks such as AutoGen, LangChain, and CrewAI have emerged as key players, each serving specific needs in the realm of AI development and deployment.\n",
       "\n",
       "One of the most compelling entrants in the AI agent landscape is Microsoft‚Äôs **AutoGen**, which is designed for multi-agent collaborative tasks. Its event-driven architecture allows it to handle complex interactions effectively. Since its launch in September 2023, it has garnered significant attention, achieving over 45,000 stars on GitHub. Organizations like Novo Nordisk have adopted AutoGen, notably due to its distinguished performance on benchmarks like GAIA, which assesses the effectiveness of collaborative AI solutions over traditional single-agent systems. This framework emphasizes not merely performance but the ability to manage multiple agents working together harmoniously, making it especially suitable for enterprise-level applications.\n",
       "\n",
       "The **LangChain** framework stands out as one of the most powerful tools for building AI agents, particularly those powered by large language models (LLMs). It allows developers to create sophisticated workflows by chaining together prompts, models, memory, and external tools, thus facilitating dynamic and versatile agent capabilities. Developers find LangChain's flexibility advantageous, as it integrates various components into streamlined workflows that enhance the efficiency of building intelligent systems. With its increasing adoption, LangChain is positioned as a frontrunner in the AI agent framework space, heralding profound implications for how developers approach agent-based solutions.\n",
       "\n",
       "On the more user-friendly side, **CrewAI** is designed with beginners in mind. Its no-code interface makes it accessible for rapid prototyping, allowing users to deploy AI agents quickly without requiring extensive programming knowledge. Equipped with ready-made templates, CrewAI reduces the entry barriers for organizations looking to leverage AI capabilities without a steep learning curve. This accessibility makes it particularly appealing for small businesses or startups, which may lack the resources to invest heavily in sophisticated AI development.\n",
       "\n",
       "Additionally, the **IBM AI Agent Frameworks** provide a range of choices suitable for different businesses. They offer both beginner-friendly options like CrewAI and more complex frameworks for seasoned developers, like LangGraph. This tiered structure allows businesses to select the framework that best matches their operational needs and technical expertise. Guides and insights from IBM help organizations navigate this choice, ensuring they understand the capabilities and limitations of each framework to make informed decisions.\n",
       "\n",
       "A comprehensive comparison of these frameworks reveals that the best choice often hinges on the specific use cases, team capabilities, and desired functionalities. In practical terms, organizations must consider whether they need a simple, lower-barrier solution or a multi-faceted, powerful framework capable of handling complex tasks and collaboration among multiple agents.\n",
       "\n",
       "In summary, the landscape of AI agent frameworks in 2023 is diverse, catering to a wide range of user needs from beginner-friendly systems to advanced collaborative tools capable of tackling complex tasks. The increasing complexity and specificity of these frameworks reflect the rapidly advancing nature of AI technology and the pressing need for effective solutions across industries.\n",
       "\n",
       "### Sources\n",
       "[1] Top 9 AI Agent Frameworks as of July 2025 | Shakudo ‚Äî https://www.shakudo.io/blog/top-9-ai-agent-frameworks  \n",
       "[2] Top 7 Free AI Agent Frameworks | Botpress ‚Äî https://botpress.com/blog/ai-agent-frameworks  \n",
       "[3] The Best AI Agents in 2025: Tools, Frameworks, and Platforms Compared | DataCamp ‚Äî https://www.datacamp.com/blog/best-ai-agents  \n",
       "[4] AI Agent Frameworks: Choosing the Right Foundation for Your Business | IBM ‚Äî https://www.ibm.com/think/insights/top-ai-agent-frameworks  \n",
       "\n",
       "</details>\n",
       "\n",
       "<details><summary><b>Summary 2</b></summary>\n",
       "\n",
       "Exploring the landscape of AI agent frameworks reveals a wealth of options that cater to diverse needs across various applications. Current discussions highlight several promising contenders, among which LangChain, AutoGen, and CrewAI are frequently noted for their robust capabilities. Each framework offers unique features, targeting specific use cases and catering to different user expertise levels. Evaluating these frameworks involves looking at their strengths in multi-agent collaboration, flexibility, usability, and integration into existing systems.\n",
       "\n",
       "### Key Frameworks and Their Features\n",
       "\n",
       "1. **LangChain**: This open-source framework stands out due to its strong emphasis on creativity and versatility for AI developers. It provides an extensive library that supports complex applications and interacts seamlessly with various tools, enabling rich workflows and agent interactions. LangChain is particularly well-suited for AI applications in enterprise environments, thanks to its modular design that allows developers to customize functionalities according to specific requirements.\n",
       "\n",
       "2. **AutoGen**: Developed by Microsoft, AutoGen is praised for its straightforwardness and accessibility, making it an excellent choice for users with varying levels of technical expertise. It supports automation tasks effectively, allowing for quick deployment of AI agents. Detailed comparisons underscore its balance between ease of use and the rich feature set it provides, making it a viable choice for both developers and businesses seeking to leverage AI in operational tasks.\n",
       "\n",
       "3. **CrewAI**: Known for its strong collaborative capabilities, CrewAI is tailored for projects that require multiple AI agents working in tandem. This framework is lauded for handling complex interactions among agents, making it ideal for applications where teamwork and coordination are paramount. Users appreciate its user-friendly interface and the depth of documentation available, which helps new users get up and running quickly.\n",
       "\n",
       "### Comparative Insights and Recommendations\n",
       "\n",
       "When evaluating these frameworks, experts stress the importance of aligning the choice with specific use cases and technical capabilities. For instance, while LangChain excels in applications requiring intricate workflows, users dealing with simpler tasks may favor AutoGen for its ease of use. Similarly, teams looking to create collaborative environments may find CrewAI's features indispensable. The choice often hinges not only on the technical specifications of the frameworks but also on the long-term goals for AI integration within enterprises.\n",
       "\n",
       "In addition to the leading frameworks, recent analyses also include comparisons of emerging platforms, such as MetaGPT and various alternatives discussed in forums. These alternatives are useful in niches where mainstream frameworks may not offer the required depth or flexibility. For developers focused on cutting-edge applications, keeping tabs on these rising stars ensures they remain at the forefront of technology advancements.\n",
       "\n",
       "The consensus among experts emphasizes a modular architecture as a critical feature for any AI agent framework, allowing developers to build and adapt their applications dynamically. Furthermore, compatibility with large language models (LLMs) and real-time performance capabilities are highlighted as essential for interactive AI applications that rely heavily on user engagement and instantaneous decision-making.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "The discussions around the best AI agent frameworks showcase a vibrant ecosystem characterized by innovation and adaptability. By considering the distinct strengths and applications of top frameworks such as LangChain, AutoGen, and CrewAI, users can make informed choices that align with their projects' objectives. As technology continues to evolve, staying updated on comparisons will be crucial for anyone involved in AI development or implementation to ensure they leverage the best tools available for their specific contexts.\n",
       "\n",
       "### Sources\n",
       "[1] AI agent frameworks : which one is best ? ‚Äî https://www.linkedin.com/pulse/ai-agent-frameworks-which-one-best-finecortex-lajve  \n",
       "[2] Best Agentic AI Frameworks Compared 2025 Guide - tkxel ‚Äî https://tkxel.com/blog/best-agentic-ai-frameworks-comparison/  \n",
       "[3] 11 Best AI Agent Alternatives & Competitors (2025) ‚Äî https://manus.so/post/jje032hz  \n",
       "[4] 10 Top AI Agent Frameworks Unveiled for 2025 - Fusion Chat ‚Äî https://fusionchat.ai/news/10-top-ai-agent-frameworks-unveiled-for-2025  \n",
       "\n",
       "</details>\n",
       "\n",
       "<details><summary><b>Summary 3</b></summary>\n",
       "\n",
       "In 2023, numerous AI frameworks emerged as dominant tools for developers and researchers, catering to a wide range of machine learning and deep learning tasks. The key frameworks that continue to shape the field include TensorFlow, PyTorch, Keras, and Scikit-Learn. Each framework comes with its own strengths, features, and applications, making it essential to understand their performance metrics thoroughly when evaluating which to use for specific AI projects.\n",
       "\n",
       "### Key Frameworks and Their Features\n",
       "\n",
       "**TensorFlow** remains one of the most popular choices among AI developers. It is an open-source library primarily designed for deep learning, but it is versatile enough to support a broader range of machine learning tasks. TensorFlow's comprehensive ecosystem includes libraries for various parts of the AI workflow, such as Keras for simplifying neural network constructs and TensorFlow Lite for mobile and embedded applications. In terms of performance, it is known for its scalability and extensive community support, which is vital for troubleshooting and improvements.\n",
       "\n",
       "**PyTorch** has also gained substantial traction, especially in the research community. Its dynamic computation graph offers greater flexibility, making it easier for experimenting with novel architectures. Many practitioners favor PyTorch for its intuitive design and ease of use, which can significantly enhance productivity when developing and refining deep learning models. In benchmark tests, PyTorch often competes closely with TensorFlow, demonstrating similar or sometimes superior performance, particularly for specific applications like natural language processing.\n",
       "\n",
       "**Keras**, now integrated as an official API into TensorFlow, is an abstraction layer that simplifies building and training deep learning models. Its user-friendly interface allows developers, particularly those new to AI, to prototype models quickly. Keras is focused on enabling fast experimentation and is widely appreciated for its straightforward documentation and ease of understanding. This makes Keras an ideal choice for those who prioritize development speed and simplicity without compromising on model performance.\n",
       "\n",
       "Another important framework is **Scikit-Learn**, which is specifically designed for classical machine learning algorithms. Scikit-Learn excels in pre-processing data, model selection, and evaluation, making it a go-to choice for data scientists working with standard analytical tasks rather than deep learning. Its performance is consistently validated across various benchmarks, providing accessible implementations of algorithms. This framework's efficiency and user-friendly features are vital for practitioners aiming to produce reliable models with less complexity.\n",
       "\n",
       "### Performance Metrics and Evaluation Criteria\n",
       "\n",
       "When evaluating AI frameworks, specific performance metrics and evaluation criteria are critical to define which framework suits a project best. Speed, scalability, and ease of deployment are primary metrics. **Speed** refers to the framework‚Äôs ability to process large datasets quickly, which is crucial for deep learning models that require extensive computations. Benchmarks often gauge how fast frameworks can train models and handle updates, contributing to their overall reliability.\n",
       "\n",
       "**Scalability** is another essential factor, particularly for applications requiring robust solutions that can adapt to growing data sizes and algorithmic complexity. TensorFlow, for instance, is designed to scale easily from a single device to distributed setups across multiple machines, which is beneficial for large organizations or massive datasets. **Ease of deployment** is also regarded highly; frameworks facilitating straightforward export to various environments (e.g., mobile, cloud) gain an edge in practical implementations.\n",
       "\n",
       "**Community support** and **documentation** also play a vital role in the evaluation process. An active community can provide resources, plugins, and troubleshooting experiences, augmenting the framework's capabilities. Detailed and accessible documentation encourages user empowerment, which is especially important for newcomers to AI development.\n",
       "\n",
       "### Emerging Trends and Comparative Insights\n",
       "\n",
       "As frameworks evolve, new trends are emerging. A relatively new concept is the integration of different frameworks and tools to unify the strengths of multiple libraries. This trend seeks to address specific shortfalls of one framework with the assets of another, encouraging a more modular approach to model development. Additionally, the rise of **AI agents**, which automate AI processes, represents another paradigm shift currently capturing attention. Platforms like LangChain and CrewAI are being discussed as effective environments for developing complex agents that harness the power of established frameworks, promoting greater efficiency in operations.\n",
       "\n",
       "Evaluating the effectiveness of these frameworks in 2023 leads to frequently updated benchmarks that inform developers on which tools remain competitive or are fast becoming industry standards. Reports and surveys, like those from Stack Overflow, highlight how developers perceive AI frameworks, examining their usage and preference trends within the community. For instance, a substantial proportion of developers reported a preference for frameworks that facilitate ease of use and effective support, emphasizing practical applications over theoretical robustness.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "In summary, the landscape of AI frameworks as of 2023 illustrates a continuing evolution toward flexibility, user-centric design, and integration of various technologies. Selecting the right framework encompasses more than just performance rankings; it involves understanding the specific needs of a project, evaluating metrics that matter, and considering broader trends in AI technology. TensorFlow, PyTorch, Keras, and Scikit-Learn represent stalwarts in the field, distinguished by their performance, community engagement, and ease of use. As AI continues to develop rapidly, these frameworks and their protocols will inevitably adapt, prompting ongoing discussions about their efficacy and future applications.\n",
       "\n",
       "### Sources\n",
       "\n",
       "[1] Top 6 AI Frameworks That Developers Should Learn in 2023 ‚Äî https://www.linkedin.com/pulse/top-6-ai-frameworks-developers-should-learn-2023-souvik-bose  \n",
       "[2] The Top 16 AI Frameworks and Libraries: A Beginner's Guide ‚Äî https://www.datacamp.com/blog/top-ai-frameworks-and-libraries  \n",
       "[3] Top 10 AI Libraries and Frameworks Every Beginner Should Know ‚Äî https://medium.com/predict/top-10-ai-libraries-and-frameworks-every-beginner-should-know-b477933afd03  \n",
       "[4] Comparing AI Frameworks: How to Decide If You Need ... ‚Äî https://secureframe.com/blog/ai-frameworks  \n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Executive Summary\n",
       "\n",
       "This report provides an in-depth analysis of the leading AI agent frameworks in 2023, including AutoGen, LangChain, and CrewAI. Each framework is evaluated for its strengths, target user demographics, and overall suitability for various applications. A comparative analysis reveals that the diversity in capabilities among these frameworks highlights the necessity of aligning framework choices with specific user needs and operational goals, ultimately paving the way for enhanced AI integration across industries.\n",
       "\n",
       "# Introduction\n",
       "\n",
       "The rapid advancement of artificial intelligence has led to the emergence of numerous AI agent frameworks tailored for diverse applications. With these frameworks, developers can create more efficient and capable AI systems. This report explores the top frameworks currently dominating the market, focusing on their functionalities and the specific needs they fulfill.\n",
       "\n",
       "# Overview of AI Agent Frameworks\n",
       "\n",
       "AI agent frameworks serve as foundational tools that facilitate the development and deployment of AI functionalities, enabling developers to build applications that can understand, process, and respond to user inputs and operational commands effectively.\n",
       "\n",
       "## Importance of AI Agent Frameworks in Modern Development\n",
       "\n",
       "Today, selecting the right AI agent framework is crucial for ensuring the success of AI integration in various sectors. As technologies evolve, frameworks must support automation, user engagement, and a seamless development experience.\n",
       "\n",
       "## Criteria for Evaluating AI Frameworks\n",
       "\n",
       "When determining the most suitable AI agent frameworks, several criteria must be considered:\n",
       "- **Usability**: How accessible is the framework for different user expertise levels?\n",
       "- **Performance**: Frameworks should enable efficient computation and responsiveness.\n",
       "- **Scalability**: Flexibility to adapt to growing user needs is vital.\n",
       "- **Community Support**: Strong community backing fosters innovation and troubleshooting.\n",
       "\n",
       "# Key AI Agent Frameworks\n",
       "\n",
       "## AutoGen\n",
       "- **Overview and Adoption**: Developed by Microsoft and launched in September 2023, AutoGen focuses on multi-agent collaborative tasks. Organizations like Novo Nordisk have already adopted it, indicating its market appeal.\n",
       "- **Strengths and Applications**: AutoGen excels in handling complex interactions, making it suitable for enterprise applications that require robust collaboration among agents. This framework's event-driven architecture is particularly noteworthy for its effectiveness in multi-agent scenarios.\n",
       "\n",
       "## LangChain\n",
       "- **Features and Capabilities**: LangChain is recognized for its powerful tools for building AI agents utilizing large language models (LLMs). It allows developers to construct sophisticated workflows by chaining prompts and models seamlessly.\n",
       "- **User Demographics**: Its strength in enabling intricate workflows positions LangChain as a strong choice for enterprise-focused applications, appealing to developers needing flexibility in design.\n",
       "\n",
       "## CrewAI\n",
       "- **Accessibility and No-Code Solutions**: CrewAI prioritizes user-friendly design, featuring a no-code interface that allows users to deploy AI agents without extensive programming knowledge. This makes it appealing for smaller businesses and startups.\n",
       "- **Target Audience and Use Cases**: Equipped with ready-made templates, CrewAI is particularly effective for those looking to prototype quickly and engages users with varying levels of technical expertise.\n",
       "\n",
       "# Comparative Analysis of AI Agent Frameworks\n",
       "\n",
       "## Usability and Learning Curve\n",
       "- **Beginner-Friendly Options vs. Advanced Capabilities**: While frameworks like AutoGen and CrewAI cater to those new to AI development with their approachable interfaces, LangChain is designed for users with advanced skills, enabling complex task management.\n",
       "\n",
       "## Performance Metrics and Evaluation Criteria\n",
       "- **Speed**: Essential for real-time applications, frameworks must deliver quick processing times.\n",
       "- **Scalability**: Frameworks must accommodate larger datasets and adapt as operational complexity grows.\n",
       "- **Community Support**: A robust community provides essential resources, enhancing user experience and problem resolution.\n",
       "\n",
       "# Emerging Frameworks and Trends\n",
       "\n",
       "## New Players in the AI Framework Space\n",
       "- Recent analysis also highlighted the emergence of platforms such as MetaGPT, which provide promising alternatives for specific niches not fully covered by mainstream frameworks.\n",
       "\n",
       "## Modular Architecture and Integration of Tools\n",
       "- A combined and modular approach is becoming a trend, allowing developers to leverage the strengths of multiple frameworks.\n",
       "\n",
       "# Conclusion\n",
       "\n",
       "As AI frameworks continue to evolve, it is critical to stay informed about the latest developments to leverage the best tools tailored for specific needs. The current landscape showcases a vibrant selection of frameworks, each offering unique strengths that cater to various user needs.\n",
       "\n",
       "# Recommendations\n",
       "\n",
       "To ensure successful AI integration, organizations should closely assess their specific requirements and select frameworks that align with their operational goals. For broader projects requiring multiple functionalities, frameworks like LangChain and AutoGen are recommended. Conversely, for rapid prototyping and less complex need, CrewAI represents a compelling option.\n",
       "\n",
       "# Follow-Up Research Topics\n",
       "- The future of AI agent frameworks: Trends and predictions.\n",
       "- Comparative analysis of modular versus monolithic architectures in AI.\n",
       "- User adoption patterns of AI frameworks in small vs. large enterprises.\n",
       "- The impact of community support on the effectiveness of AI frameworks.\n",
       "- Evaluating the relationship between framework performance metrics and real-world applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### References\n",
       "\n",
       "1. [Top 9 AI Agent Frameworks as of July 2025 | Shakudo](https://www.shakudo.io/blog/top-9-ai-agent-frameworks)\n",
       "2. [Top 7 Free AI Agent Frameworks | Botpress](https://botpress.com/blog/ai-agent-frameworks)\n",
       "3. [The Best AI Agents in 2025: Tools, Frameworks, and Platforms Compared | DataCamp](https://www.datacamp.com/blog/best-ai-agents)\n",
       "4. [AI Agent Frameworks: Choosing the Right Foundation for Your Business | IBM](https://www.ibm.com/think/insights/top-ai-agent-frameworks)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# 9) Example usage (Jupyter: just `await main()`; script: `asyncio.run(main())`)\n",
    "# ======================================================================================\n",
    "\n",
    "plan, mini_summaries, report = await run_research(\"List of AI Agent frameworks  sorted by the top ones\")\n",
    "show_plan(plan)\n",
    "show_mini_summaries(mini_summaries)\n",
    "show_report(report, mini_summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ======================================================================================\n",
    "# # 10) Email test\n",
    "# # ======================================================================================\n",
    "\n",
    "\n",
    "# from agents import Runner\n",
    "# import html\n",
    "\n",
    "# query = \"List of AI Agent frameworks in 2025\"\n",
    "# subject = f\"Deep Research ‚Äì {query}\"\n",
    "\n",
    "# html_body = f\"\"\"\n",
    "# <h1>{html.escape(subject)}</h1>\n",
    "# <hr/>\n",
    "# <pre style=\"white-space:pre-wrap;font-family:ui-monospace, SFMono-Regular, Menlo, Consolas;\">\n",
    "# {html.escape(report.markdown_report)}\n",
    "# </pre>\n",
    "# \"\"\"\n",
    "\n",
    "# await Runner.run(\n",
    "#     email_agent,\n",
    "#     f\"\"\"Send this as an HTML email using your tool.\n",
    "# subject: {subject}\n",
    "# html_body:\n",
    "# <<<HTML\n",
    "# {html_body}\n",
    "# HTML\"\"\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saket\\AppData\\Local\\Temp\\ipykernel_10844\\157723431.py:119: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Research Chat\", height=350, type=\"tuples\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://c9ea5cb89185c086cc.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c9ea5cb89185c086cc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nSTANDALONE NOTE:\\nReplace the `try/except` block with:\\n\\n    from your_module import run_research\\n\\nEnsure that `your_module.run_research` matches the signature used above.\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning...\n",
      "\u001b[36m‚ÑπÔ∏è  Planned search phrases:\u001b[0m\n",
      "  1. \u001b[1mOpenAI agents SDK documentation\u001b[0m \u001b[2m‚Äî To find the official documentation and resources for using OpenAI's agents SDK.\u001b[0m\n",
      "  2. \u001b[1mOpenAI agents SDK features updates\u001b[0m \u001b[2m‚Äî To gather information on the latest features and updates related to OpenAI agents SDK.\u001b[0m\n",
      "  3. \u001b[1mOpenAI agents SDK tutorials community\u001b[0m \u001b[2m‚Äî To explore community discussions, tutorials, and examples of how to implement the OpenAI agents SDK in projects.\u001b[0m\n",
      "Searching...\n",
      "\u001b[35müîé Searching: OpenAI agents SDK documentation\u001b[0m\n",
      "\u001b[35müîé Searching: OpenAI agents SDK features updates\u001b[0m\n",
      "\u001b[35müîé Searching: OpenAI agents SDK tutorials community\u001b[0m\n",
      "\u001b[32m‚úÖ Done: OpenAI agents SDK documentation\u001b[0m\n",
      "\u001b[32m‚úÖ Done: OpenAI agents SDK features updates\u001b[0m\n",
      "\u001b[32m‚úÖ Done: OpenAI agents SDK tutorials community\u001b[0m\n",
      "Synthesizing...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======================================================================================\n",
    "# 11) Gradio demo (optional)\n",
    "# ======================================================================================\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Gradio UI for your Deep Research pipeline.\n",
    "\n",
    "This app assumes you already have the orchestration helpers defined in the same Python\n",
    "process (plan_searches, perform_searches, write_report, run_research) or imported from\n",
    "your module. If you ran your earlier code in the same session (e.g., Jupyter), this\n",
    "file can import them directly with a `from your_module import run_research`.\n",
    "\n",
    "If you prefer a fully-standalone app, see the STANDALONE NOTE near the bottom for\n",
    "how to swap in an import.\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "try:\n",
    "    run_research  # type: ignore[name-defined]\n",
    "except NameError:\n",
    "    raise RuntimeError(\n",
    "        \"run_research(query) is not defined in this process.\\n\"\n",
    "        \"Import it here, e.g.: from deep_research import run_research\\n\"\n",
    "        \"Or run this app in the same kernel where you defined run_research.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _plan_to_rows(plan) -> List[list]:\n",
    "    \"\"\"Turn WebSearchPlan into rows for a DataFrame-friendly structure (list of lists).\"\"\"\n",
    "    rows: List[list] = []\n",
    "    try:\n",
    "        for i, it in enumerate(plan.searches, 1):\n",
    "            rows.append([i, getattr(it, \"query\", \"\"), getattr(it, \"reason\", \"\")])\n",
    "    except Exception:\n",
    "        pass\n",
    "    return rows\n",
    "\n",
    "\n",
    "def _citations_to_md(report) -> str:\n",
    "    \"\"\"Render final citations as Markdown numbered list.\"\"\"\n",
    "    if not getattr(report, \"final_citations\", None):\n",
    "        return \"\"\n",
    "    lines = [\"\\n### Sources\\n\"]\n",
    "    for idx, c in enumerate(report.final_citations, 1):\n",
    "        title = getattr(c, \"title\", None) or \"Source\"\n",
    "        url = getattr(c, \"url\", \"\")\n",
    "        if url:\n",
    "            lines.append(f\"{idx}. [{title}]({url})\")\n",
    "        else:\n",
    "            lines.append(f\"{idx}. {title}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def _write_markdown_to_file(md: str, folder: str = \".\") -> str:\n",
    "    ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    path = os.path.join(folder, f\"deep_research_{ts}.md\")\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(md)\n",
    "    return path\n",
    "\n",
    "\n",
    "async def stream_research(chat_history: List[Tuple[str, str]], topic: str, progress=gr.Progress(track_tqdm=False)):\n",
    "    \"\"\"\n",
    "    Chat-like streaming handler. Yields intermediate updates as tuples compatible with Chatbot(type=\"tuples\").\n",
    "    \"\"\"\n",
    "    history = list(chat_history or [])\n",
    "    history.append((topic, \"Starting deep research...\"))\n",
    "    yield history, [], \"\", \"\", \"\", None\n",
    "\n",
    "    progress(0.05, desc=\"Planning searches‚Ä¶\")\n",
    "    history[-1] = (topic, \"Planning searches‚Ä¶\")\n",
    "    yield history, [], \"\", \"\", \"\", None\n",
    "\n",
    "    progress(0.12, desc=\"Running pipeline‚Ä¶ (this may take a bit)\")\n",
    "    plan, mini_summaries, report = await run_research(topic)  # type: ignore[name-defined]\n",
    "\n",
    "    progress(0.55, desc=\"Formatting results‚Ä¶\")\n",
    "    plan_rows = _plan_to_rows(plan)\n",
    "    history[-1] = (topic, \"Searches planned. Gathering and synthesizing‚Ä¶\")\n",
    "    yield history, plan_rows, \"\", \"\", \"\", None\n",
    "\n",
    "    if mini_summaries:\n",
    "        parts = [\"## Mini-summaries\"]\n",
    "        for i, s in enumerate(mini_summaries, 1):\n",
    "            parts.append(f\"<details><summary><b>Summary {i}</b></summary>\\n\\n{s}\\n\\n</details>\")\n",
    "        mini_md = \"\\n\\n\".join(parts)\n",
    "    else:\n",
    "        mini_md = \"(No mini-summaries produced)\"\n",
    "\n",
    "    yield history, plan_rows, mini_md, \"\", \"\", None\n",
    "\n",
    "    report_md = getattr(report, \"markdown_report\", \"\")\n",
    "    sources_md = _citations_to_md(report)\n",
    "\n",
    "    full_md = report_md + (\"\\n\\n\" + sources_md if sources_md else \"\")\n",
    "    file_path = _write_markdown_to_file(full_md)\n",
    "\n",
    "    history[-1] = (topic, \"Done ‚úÖ\")\n",
    "    progress(1.0, desc=\"Complete\")\n",
    "    yield history, plan_rows, mini_md, report_md, sources_md, file_path\n",
    "\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # üîé Deep Research (Gradio)\n",
    "        Enter a topic and I'll plan searches, gather snippets, and synthesize a long-form report.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(label=\"Research Chat\", height=350, type=\"tuples\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        topic = gr.Textbox(placeholder=\"e.g., Latest AI Agent frameworks in 2025\", label=\"Topic\", lines=1)\n",
    "        go = gr.Button(\"Run Research\", variant=\"primary\")\n",
    "\n",
    "    with gr.Row():\n",
    "        plan_table = gr.Dataframe(headers=[\"#\", \"query\", \"reason\"], label=\"Planned web searches\", interactive=False)\n",
    "\n",
    "    mini_md = gr.Markdown(label=\"Mini-summaries\")\n",
    "    report_md = gr.Markdown(label=\"Synthesis report (Markdown)\")\n",
    "    sources_md = gr.Markdown(label=\"Sources\")\n",
    "\n",
    "    with gr.Row():\n",
    "        dl = gr.DownloadButton(label=\"Download Markdown\", value=None)\n",
    "\n",
    "    state = gr.State([])\n",
    "\n",
    "    go.click(\n",
    "        fn=stream_research,\n",
    "        inputs=[state, topic],\n",
    "        outputs=[chatbot, plan_table, mini_md, report_md, sources_md, dl],\n",
    "        show_progress=True,\n",
    "    ).then(lambda h: h, inputs=chatbot, outputs=state)\n",
    "\n",
    "    gr.Examples([\n",
    "        [\"Latest AI Agent frameworks in 2025\"],\n",
    "        [\"State of multimodal RAG for e-commerce\"],\n",
    "        [\"Carbon accounting tools for utilities in 2025\"]\n",
    "    ], inputs=[topic])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share = True)\n",
    "\n",
    "\"\"\"\n",
    "STANDALONE NOTE:\n",
    "Replace the `try/except` block with:\n",
    "\n",
    "    from your_module import run_research\n",
    "\n",
    "Ensure that `your_module.run_research` matches the signature used above.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deep_research_project)",
   "language": "python",
   "name": "deep_research_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
